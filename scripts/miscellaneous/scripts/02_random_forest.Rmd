---
title: "Random forest and the quest of finding important differentiating features"
author: "Anqi Dai"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F) 
```

```{r}
library(tidyverse)
library(randomForest)
library(ggpubr)
library(kableExtra)
library(arrangements)
```

* What is random in random forest?

  + The random forest is a classification algorithm consisting of many decisions trees. It uses bagging and feature randomness when building each individual tree to try to create an uncorrelated forest of trees whose prediction by committee is more accurate than that of any individual tree. 
  + Please refer to this youtube video which provides excellent explanation: https://www.youtube.com/watch?v=J4Wdy0Wc_xQ
  
* What is random forest good for?

  + Random forest is a flexible, easy to use machine learning algorithm that produces, even without hyper-parameter tuning, a great result most of the time. It is also one of the most used algorithms, because of its simplicity and diversity (it can be used for both *classification* and *regression* tasks).

# Hana's mait cell project data

```{r}
# it contains all the pheno and all the genera info
# this table has all the essential information, deidentify here
dat <- read_csv('../data/pheno_unconventional_periengr_d30_allsamples.csv') %>% 
  mutate(mrn = as.numeric(as.factor(mrn))) %>% 
  mutate(mrn = str_glue("P{str_pad(mrn, 3, 'left', '0')}"))

dat %>%
  count(mrn)

range(dat$sample_day)
```
 
# Clean the pheno table 

**Factorize your grouping variable**

```{r}
# the categorical has to be factored (for classification)
pheno <- dat %>% 
  distinct(mrn, MAIT_reconstitution, MAIT_Vd2) %>% 
  mutate(MAIT_reconstitution = factor(MAIT_reconstitution),
         MAIT_Vd2 = factor(MAIT_Vd2)) %>% 
  arrange(mrn)

pheno %>% 
  count(MAIT_reconstitution)

pheno %>% 
  count(MAIT_Vd2)
```

# Get the median relab for top N most abundant genera

```{r}
cts_median <- dat %>% 
  select(mrn, sampleid, Abiotrophia:Xanthomonas) %>% 
  gather('genus', 'relab',names(.)[3]:names(.)[ncol(.)] ) %>% 
  group_by(mrn, genus) %>% 
  summarise(median_relab = median(relab)) %>% 
  spread('mrn', 'median_relab') 
  

# get the top most abundant N genera
N <- 50

cts_median_top <- cts_median %>% 
  mutate(genus_sum = rowSums(.[2:ncol(.)])) %>% 
  arrange(desc(genus_sum)) %>% 
  top_n(n = N) %>% 
  select(-genus_sum) %>% 
  gather('mrn', 'med_relab', names(.)[2]:names(.)[ncol(.)]) %>% 
  spread('genus', 'med_relab') %>% 
  arrange(mrn) %>% 
  full_join(pheno, by = 'mrn') %>% 
  select(-mrn) 

colnames(cts_median_top)
```

# Build the random forest

##  For MAIT_reconstitution

```{r}
set.seed(100) # so that if we use the same seed we are gonna get the same "random" result.

mod_recon <- randomForest(MAIT_reconstitution ~ ., data = cts_median_top %>% select(-MAIT_Vd2), importance = T)

mod_recon

# visualize the importance of the features
varImpPlot(mod_recon)

# plot the err rate change
mod_recon  %>% 
  pluck('err.rate') %>% 
  as.data.frame() %>% 
  mutate(ntree = seq(1, nrow(.))) %>% 
  gather(key = 'type', value = 'ERR', names(.)[1]:names(.)[ncol(.)-1]) %>% 
  ggline(x = 'ntree', y = 'ERR', color = 'type', palette = 'jama') +
  labs(x = 'Number of trees', 
       y = 'Error rate')
```

## For MAIT_Vd2

```{r}
set.seed(456)

mod_vd2 <- randomForest(MAIT_Vd2 ~ ., data = cts_median_top %>% select(-MAIT_reconstitution), importance = T)

mod_vd2

# visualize the importance of the features
varImpPlot(mod_vd2)

# plot the err rate change
mod_vd2  %>% 
  pluck('err.rate') %>% 
  as.data.frame() %>% 
  mutate(ntree = seq(1, nrow(.))) %>% 
  gather(key = 'type', value = 'ERR', names(.)[1]:names(.)[ncol(.)-1]) %>% 
  ggline(x = 'ntree', y = 'ERR', color = 'type', palette = 'jama') +
  labs(x = 'Number of trees', 
       y = 'Error rate')
```

##### In general neither of these worked, since the error rate ends pretty high for most of them. But what should it look like when it works??

# Test: use RF to classify pre and post or predict day relative to transplant in NEJM cohort patients

```{r}
knitr::include_graphics('/Volumes/vandenBrinkLab/Angel_Dai/NEJM_tsne.png')
```


```{r}
# Load all the necessary tables from the database
source('~/db_connect_simple.R')
connect_database(config_file = '~/dbConfig.txt')


get_table_from_database_predefined_filter('asv_counts_ag')
ANNOT <- get_table_from_database('asv_annotation_blast_ag')

get_table_from_database("multivariate_clean_frozen_set_ag")
get_table_from_database("frozen_set_ag")
```

```{r}
# look at the data and select the pre and post time period
frozen_set_ag %>% 
  count(institution)

frozen_set_ag %>% 
  filter(institution == 'MSK_allo') %>% 
  filter(day_relative_to_hct < 100) %>% 
  gghistogram('day_relative_to_hct', bins = 100)

# [-20,-10] and [15, 25] in msk patients samples 
set.seed(988)
N_samp <- 125
  
stb_sub <- frozen_set_ag %>% 
  filter(institution == 'MSK_allo') %>% 
  filter(day_relative_to_hct %in% -20:-10 | day_relative_to_hct %in% 15:25 ) %>% 
  mutate(grp = if_else(day_relative_to_hct > 0, 'post', 'pre')) %>% 
  # because in peri engraftment time, one patient may have multiple samples and those are highly correlated, so only include one earliest sample for each patient in each group (pre and post)
  arrange(patient_id, grp, day_relative_to_hct) %>% 
  distinct(patient_id, grp, .keep_all = T) %>% 
  # sampling N_samp rows in each group
  split(.$grp) %>% 
  map_dfr(~ sample_n(tbl = ., size = N_samp))  %>% 
  mutate(grp = factor(grp, levels = c('pre','post')))

stb_sub %>% 
  count(grp)

colnames(stb_sub)
```

```{r}
# prepare a counts table of the relative abundance for the top 50 most abundant genera 

cts <- asv_counts_ag %>% 
  filter(sampleid %in% stb_sub$sampleid) %>% 
  select(asv_key, sampleid, count) %>% 
  spread(key = 'sampleid', value = 'count', fill = 0) %>% 
  arrange(asv_key)  

# how many samples counts in the db
ncol(cts) - 1

# to get the taxa level of genus for us to summarize later
annot <- ANNOT %>% 
  filter(asv_key %in% cts$asv_key) %>% 
  mutate(ordr =  if_else(ordr == '', str_glue('of_class_{class}'), ordr),
         family =  if_else(family == '', str_glue('of_order_{ordr}'), family),
         genus =  if_else(genus == '', str_glue('of_family_{family}'), genus),
         species =  if_else(species == '', str_glue('of_genus_{genus}'), species)) %>% 
  mutate(taxa_genus = str_glue('g__{genus}'))


# replace the asv_key with the genus taxa level
# summarize from asv level to genus level
# get the relative abundance for the genera
cts_all <- cts %>% 
  full_join(annot %>%  select(asv_key, taxa_genus), by  = 'asv_key') %>% 
  select(-asv_key) %>% 
  gather(key = 'sampleid', value = 'count', names(.)[1]:names(.)[ncol(.) - 1]) %>% 
  group_by(sampleid, taxa_genus) %>% 
  summarise(cnt = sum(count)) %>% 
  # get the total count from the db to calculate the relab
  left_join(asv_counts_ag %>% distinct(sampleid,count_total ), by = 'sampleid') %>% 
  mutate(relab = cnt/count_total) %>% 
  select(sampleid, taxa_genus, relab) 
  
# get the top 50 genera ranked by their total abundance
N <- 50

topN_genus <- cts_all %>% 
  group_by(taxa_genus) %>% 
  summarise(genus_sum = sum(relab)) %>% 
  arrange(desc(genus_sum)) %>% 
  top_n(N) %>% 
  pull(taxa_genus)

# subset out counts table to only include the top 50
cts_top <- cts_all %>% 
  filter(taxa_genus %in% topN_genus) %>% 
  spread(key = 'taxa_genus', value = 'relab') %>% 
  arrange(sampleid) 

dim(cts_top)
```


```{r}
# split to training and test set 
# training 70% of each group, test: remaining
train_num <- stb_sub %>% 
  count(grp) %>% 
  distinct(n) %>% 
  summarise(num = round(n * 0.7)) %>% 
  pull(num)

set.seed(1001)
train_samples <- stb_sub %>% 
  split(.$grp) %>% 
  map_dfr(~ sample_n(tbl = ., size = train_num)) %>% 
  pull(sampleid)

# get the counts and the pheno for the train and test set
cts_pheno <- cts_top %>% 
  inner_join(stb_sub %>% select(sampleid, day_relative_to_hct, grp), by = 'sampleid')

train_df <- cts_pheno %>% 
  filter(sampleid %in% train_samples) %>% 
  ungroup() %>% 
  select(-sampleid)

test_df <- cts_pheno %>% 
  filter(!sampleid %in% train_samples) %>% 
  ungroup() %>% 
  select(-sampleid)

colnames(train_df)
```

## Classify on pre and post

```{r}
set.seed(123)  
mod <- randomForest(grp ~ ., data = train_df %>% select(-day_relative_to_hct), importance = T) 
mod

varImpPlot(mod) 

# plot the err rate change
mod  %>% 
  pluck('err.rate') %>% 
  as.data.frame() %>% 
  mutate(ntree = seq(1, nrow(.))) %>% 
  gather(key = 'type', value = 'ERR', names(.)[1]:names(.)[ncol(.)-1]) %>% 
  ggline(x = 'ntree', y = 'ERR', color = 'type', palette = 'jco') +
  labs(x = 'Number of trees', 
       y = 'Error rate',
       title = 'Error rate')  +
  ylim(0, 1) 


# predict the grouping label on the test set
pred <- predict(mod, newdata=test_df %>% select(-day_relative_to_hct, -grp))    
pre_matrix <- table(test_df$grp, pred)
pre_matrix
```
  
## Regression to predict day_relative_to_hct which is a continuous variable
  
```{r}
# if use the day relative to transplant which is a continuous variable to do prediction
set.seed(777)   
mod_drt <- randomForest(day_relative_to_hct ~ ., data = train_df %>% select(-grp), importance = T) 
mod_drt  

#sqrt(sum((mod_drt$predicted - sub_pheno$day_relative_to_hct)^2) / nrow(sub_pheno))

# test on the test set
drt_predict <- predict(mod_drt, newdata=test_df)

data_frame(RF_predict = drt_predict, 
           true_value = test_df$day_relative_to_hct) %>% 
  ggscatter('RF_predict', 'true_value') +
  geom_abline(intercept = 0, slope = 1, color = 'red')

```

The true data is bimodal, not really continuous. So the predicted values have some deviation.

# How do we continue from the mait project

The vegan way: bray-curtis dissimilarity   


## Permanova test (global)

```{r}
set.seed(998)
library(vegan) 
cts_median_top_df <- cts_median_top %>% select(Abiotrophia:Veillonella)
pmv_mait <- adonis(cts_median_top_df ~ MAIT_reconstitution, data=cts_median_top, permutations=999, method = 'bray')
pmv_mait

pmv_vd2 <- adonis(cts_median_top_df ~ MAIT_Vd2, data=cts_median_top, permutations=999, method = 'bray')
pmv_vd2


# to see the within group dispersion
dist_pmv <- vegdist(cts_median_top_df, method = 'bray')
bd <- betadisper(dist_pmv, cts_median_top$MAIT_Vd2)
#boxplot(bd) 
anova(bd) 

colnames(cts_median_top)
```

It's good that the anova p value is not significant. That proves that the between group distance is bigger than within group distance.

## Permanova (pairwise)

```{r}
# use a loop to try all the vd2 pair combinations 
vd2_4 <- cts_median_top %>% 
  mutate(MAIT_Vd2 = as.character(MAIT_Vd2)) %>% 
  distinct(MAIT_Vd2) %>% 
  pull(MAIT_Vd2)

combi <- combinations(vd2_4, 2) %>% 
  as.data.frame() 
  
combi 
```

```{r}
set.seed(1001)
pairwise_adonis <- apply(combi, 1, function(Row){
  
  cts_median_top_sub <- cts_median_top %>% 
    filter(MAIT_Vd2 %in% c(Row[['V1']],Row[['V2']]))
  
  cts_median_top_sub_genera <- cts_median_top_sub %>% 
    select(Abiotrophia:Veillonella)

  # calculate the within group dispersion anova
  dist_pmv <- vegdist(cts_median_top_sub_genera, method = 'bray')
  bd <- betadisper(dist_pmv, cts_median_top_sub$MAIT_Vd2)
  anova_res <- anova(bd)

  # get the top N most contributing features
  sim <- simper(cts_median_top_sub_genera , group = cts_median_top_sub$MAIT_Vd2)

  genus_contri <- summary(sim) %>%
    pluck(str_glue("{Row[['V1']]}_{Row[['V2']]}")) %>%
    rownames_to_column('genus') %>%
    arrange(desc(average)) %>%
    head(n = 20)

  # the permanova
  pmv_pair_vd2 <- adonis(cts_median_top_sub_genera ~ MAIT_Vd2, data=cts_median_top_sub, permutations=999, method = 'bray')
  return(list(pw_adonis_pval = pmv_pair_vd2$aov.tab$`Pr(>F)`[1],
         anova_pval = anova_res$`Pr(>F)`[1],
         topN_feature_df = genus_contri))
  
})

# extrac the p values 
pw_adonis_pval_list <- list()
for(i in 1:nrow(combi)){
  pw_adonis_pval_list[[i]]= pairwise_adonis[[i]]$pw_adonis_pval
}


anova_pval_list <- list()
for(i in 1:nrow(combi)){
  anova_pval_list[[i]]= pairwise_adonis[[i]]$anova_pval
}


pw_adonis_pval_df <- pw_adonis_pval_list %>%
  as.data.frame() %>%
  gather('id', 'adonis_pval') %>%
  select(-id)


anova_pval_df <- anova_pval_list %>%
  as.data.frame() %>%
  gather('id', 'anova_pval') %>%
  select(-id)

pairwise_adonis_res <- bind_cols(combi, pw_adonis_pval_df, anova_pval_df) %>%
  transmute(pair = str_glue('{V1}_{V2}'),
            adonis_pval,
            anova_pval) %>%
  mutate(fdr_pw_adonis = p.adjust(adonis_pval, method = 'BH'))

pairwise_adonis_res
```

There are two pairs that have FDR < 0.05

```{r}
# the top 20 contributing features
pairwise_adonis[[1]]$topN_feature_df

pairwise_adonis[[2]]$topN_feature_df
```

 
# See the PCoA visualization  

```{r}
Row <- list(V1 = 'none', V2 = 'Vd2') # have a relatively bigger sample size
#Row <- list(V1 = 'none', V2 = 'both')
#Row <- list(V1 = 'Vd2', V2 = 'MAIT')
  
cts_median_top_sub <- cts_median_top %>% 
  filter(MAIT_Vd2 %in% c(Row[['V1']],Row[['V2']]))

cts_median_top_sub_genera <- cts_median_top_sub %>% 
  select(Abiotrophia:Veillonella)

# calculate the within group dispersion anova
dist_pmv <- vegdist(cts_median_top_sub_genera, method = 'bray')
 
bc <- cmdscale(dist_pmv, k = 2) 

data_frame(PCoA1 = bc[,1],
           PCoA2 = bc[,2],
           MAIT_Vd2 = cts_median_top_sub$MAIT_Vd2) %>% 
    ggscatter(x = 'PCoA1', y = 'PCoA2', color =  'MAIT_Vd2',  palette = 'jco') +
    labs( title = 'PCoA (BC distance)')

```

## Visualize in 3D (bonus)

If you create the required file format, you can visualize in 3D using qiime2 plugin emperor on https://view.qiime2.org/. Becasue qiime2 is external webdsite, need to deidentify!!!

```{r}
# 1. get the distance matrix
distance_matrix <- as.matrix(dist_pmv)
distance_matrix %>% write.table('data/none_vd2_BC_matrix.tsv', sep = '\t', row.names = T)

# also write out the pheno_sub to tsv
pheno_sub %>%
  # cuz they will only accept certain strings to be first column name
  rename(sampleid = mrn) %>%
  write_tsv('data/none_vd2_pheno.tsv')
```

### The below runs in terminal in qiime2 environment

If you are interested in, please go to: https://docs.qiime2.org/2020.2/ to learn.

```{bash}
# import it into qiime qza object
#qiime tools import --input-path data/none_vd2_BC_matrix.tsv  --output-path  data/none_vd2_BC_matrix.qza --type "DistanceMatrix"
  
# get the pcoa for the dist matrix
#qiime diversity pcoa --i-distance-matrix data/none_vd2_BC_matrix.qza   --o-pcoa data/none_vd2_BC_pcoa.qza
   
# visualize with emperor
#qiime emperor plot  --i-pcoa data/none_vd2_BC_pcoa.qza   --m-metadata-file data/none_vd2_pheno.tsv --o-visualization  data/none_vd2_BC_emperor.qzv
```


# Conclusions

The signal is pretty weak, meaning it's hard to differentiate the mait reconstitution and mait vd2 apart from microbiome data. Thus random forest do not appear working. 

The PCoA suggests there is a trend in separating pairs of subgroups. Collecting more samples would be helpful.

The permanova significant results could be driven by the sample size. The more samples you have the smaller the p value tends to be.


  