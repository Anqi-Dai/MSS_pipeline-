'''
This Snakefile carries out diet project work with qiime2 **LOCALLTY**

To run, source activate qiime2-2020.2
'''

rule all:
    input:
        'data/finalized/unweighted_unifrac_distance_matrix.qza'
        

#############################################################
# The diet data 
#############################################################

rule convert_dehywt_table_to_biom:
    input:
        'data/finalized/all_patients_food_dehywt_table_w_fooID_by_day.tsv'
    output:
        'data/finalized/all_patients_food_dehywt_table_w_fooID_by_day.biom'
    shell:
        'biom convert -i  {input[0]} -o {output[0]} --to-hdf5 --table-type="Table"'

rule convert_dehywt_table_to_qza:
    input:
        'data/finalized/all_patients_food_dehywt_table_w_fooID_by_day.biom'
    output:
        'data/finalized/all_patients_food_dehywt_table_w_fooID_by_day.qza'
    shell:
        'qiime tools import --input-path {input[0]} --output-path  {output[0]} --type "FeatureTable[Frequency]"' 

rule cal_unweighted_unifrac:
    input:
        cts='data/finalized/all_patients_food_dehywt_table_w_fooID_by_day.qza',
        tree='data/finalized/output_food_tree_datatree.qza'
    output:
        'data/finalized/unweighted_unifrac_distance_matrix.qza'
    shell:
        '''
        qiime diversity beta-phylogenetic \
            --i-table {input.cts} \
            --i-phylogeny {input.tree} \
            --p-metric unweighted_unifrac \
            --o-distance-matrix {output[0]}
        '''

rule pcoa_unweighted_unifrac:
    input:
        'data/finalized/unweighted_unifrac_distance_matrix.qza'
    output:
        'data/finalized/unweighted_unifrac_pcoa.qza'
    shell:
        'qiime diversity pcoa \
            --i-distance-matrix {input[0]} \
            --o-pcoa {output[0]}'

# visualize needs to use the meta table 

rule visualize_unweighted_unifrac_with_emperor_custom_axes:
    input:
        pcoa='data/finalized/unweighted_unifrac_pcoa.qza',
        meta='data/finalized/meta_data_67.tsv'
    output:
        'data/finalized/unweighted_unifrac_distance_emperor_foodDayRT.qzv'
    shell:
        '''
        qiime emperor plot \
            --i-pcoa {input.pcoa} \
            --m-metadata-file {input.meta} \
            --p-custom-axes foodDayRT \
            --o-visualization  {output[0]}
        ''' 


rule visualize_unweighted_unifrac_with_emperor_faith_pd:
    input:
        pcoa='data/finalized/unweighted_unifrac_pcoa.qza',
        meta='data/finalized/meta_data_67.tsv'
    output:
        'data/finalized/unweighted_unifrac_distance_emperor_faith_pd.qzv'
    shell:
        '''
        qiime emperor plot \
            --i-pcoa {input.pcoa} \
            --m-metadata-file {input.meta} \
            --p-custom-axes faith_pd \
            --o-visualization  {output[0]}
        ''' 



rule visualize_unweighted_unifrac_with_emperor:
    input:
        pcoa='data/finalized/unweighted_unifrac_pcoa.qza',
        meta='data/finalized/meta_data_67.tsv'
    output:
        'data/finalized/unweighted_unifrac_distance_emperor.qzv'
    shell:
        '''
        qiime emperor plot \
            --i-pcoa {input.pcoa} \
            --m-metadata-file {input.meta} \
            --o-visualization  {output[0]}
        '''

rule viz:
    input:
        'data/finalized/unweighted_unifrac_distance_emperor.qzv',
        'data/finalized/unweighted_unifrac_distance_emperor_faith_pd.qzv',
        'data/finalized/unweighted_unifrac_distance_emperor_foodDayRT.qzv'


# so that I can do a ggplot
rule export_pcoa_matrix:
    input:
        'data/finalized/unweighted_unifrac_distance_matrix.qza'
    output:
        'data/finalized/unweighted_unifrac'
    shell:
        'qiime tools export --input-path {input[0]} --output-path {output[0]}'



# longitudinal analysis

rule create_div_qza:
    input:
        'data/finalized/faith_all.tsv'
    output:
        'data/finalized/faith_all.qza'
    shell:
        '''
        qiime tools import --input-path {input[0]} --output-path  {output[0]} --type 'SampleData[AlphaDiversity]'
        '''


rule faith_alpha_volatility:
    input:
        meta='data/finalized/meta_data_67.tsv'
    output:
        'data/finalized/faith_alpha_volatility.qzv'
    shell:
        '''
        qiime longitudinal volatility \
            --m-metadata-file {input.meta} \
            --p-default-metric faith_pd \
            --p-default-group-column intensity \
            --p-state-column foodDayRT \
            --p-individual-id-column mrn \
            --o-visualization {output[0]}
        '''

# First differencing to track rate of change


rule faith_first_difference:
    input:
        meta='data/finalized/meta_data_67.tsv'
    output:
        'data/finalized/faith_first_difference.qza'
    shell:
        '''
        qiime longitudinal first-differences \
            --m-metadata-file {input.meta} \
            --p-metric faith_pd \
            --p-state-column foodDayRT \
            --p-individual-id-column mrn \
            --p-replicate-handling random \
            --o-first-differences {output[0]}
        '''


rule faith_first_difference_volatility:
    input:
        meta='data/finalized/meta_data_67.tsv',
        first_diff='data/finalized/faith_first_difference.qza'
    output:
        'data/finalized/faith_first_difference_volatility.qzv'
    shell:
        '''
        qiime longitudinal volatility \
            --m-metadata-file {input.meta} \
            --m-metadata-file {input.first_diff} \
            --p-default-metric Difference \
            --p-default-group-column intensity \
            --p-state-column foodDayRT \
            --p-individual-id-column mrn \
            --o-visualization {output[0]}
        '''


# feature volatility -- to pick out predictive features

'''
This pipeline identifies features that are predictive of a numeric metadata column, “state_column” (e.g., time), 
and plots their relative frequencies across states using interactive feature volatility plots
'''

rule feature_volatility:
    input:
        cts='data/finalized/all_patients_food_dehywt_table_w_fooID_by_day.qza',
        meta='data/finalized/meta_data_67.tsv'
    output:
        'data/finalized/cts_feature_volatility'
    shell:
        '''
        qiime longitudinal feature-volatility \
         1   --i-table {input.cts} \
            --m-metadata-file {input.meta} \
            --p-state-column faith_pd \
            --p-individual-id-column mrn \
            --p-n-jobs 4 \
            --output-dir {output[0]}
        '''

rule output:
    input:
        'data/finalized/cts_feature_volatility'








######################################################################
# the Microbiome data
######################################################################

# Train our own classifier

## import the silva OTU fasta seq and taxanomy to qiime

rule import_silva_ref_seq:
    input:
        'data/qiime/SILVA_132_QIIME_release/rep_set/rep_set_16S_only/99/silva_132_99_16S.fna'
    output:
        'data/qiime/silva_132_99.qza'
    shell:
        '''
        qiime tools import \
            --type 'FeatureData[Sequence]' \
            --input-path {input[0]} \
            --output-path {output[0]}
        '''

rule import_silva_taxonomy:
    input:
        'data/qiime/SILVA_132_QIIME_release/taxonomy/16S_only/99/majority_taxonomy_7_levels.txt'
    output:
        'data/qiime/silva_132_99_taxa.qza'
    shell:
        '''
        qiime tools import \
            --type 'FeatureData[Taxonomy]' \
            --input-format HeaderlessTSVTaxonomyFormat \
            --input-path {input[0]} \
            --output-path {output[0]}
        '''

# Extract reference reads
################################
#Here truncate at 210 cuz this
# dataset of 1002 samples look
# so
###############################

rule extract_ref_reads:
    input:
        silva_ref='data/qiime/silva_132_99.qza'
    output:
        ref_seq='data/qiime/us_ref-seqs.qza'
    shell:
        '''
        qiime feature-classifier extract-reads \
            --i-sequences {input.silva_ref} \
            --p-f-primer AYTGGGYDTAAAGNG \
            --p-r-primer CCGTCAATTYHTTTRAGT \
            --p-trunc-len 210 \
            --p-min-length 180 \
            --p-max-length 274 \
            --p-n-jobs 4 \
            --o-reads {output.ref_seq}
        '''


# train the classifier with Naive Bayes

rule fit_classifier_naive_bayes:
    input:
        ref_seq='data/qiime/us_ref-seqs.qza',
        taxonomy='data/qiime/silva_132_99_taxa.qza'
    output:
        classifier='data/qiime/us_classifier.qza'
    shell:
        '''
        qiime feature-classifier fit-classifier-naive-bayes \
            --i-reference-reads {input.ref_seq} \
            --i-reference-taxonomy {input.taxonomy} \
            --o-classifier {output.classifier}
        '''

# the above two steps are done on the cluster cuz it takes shorter time


# Test the classifier

rule test_classifier_on_our_data:
    input:
        classifier='data/qiime/us_classifier.qza',
        rep_seq='data/qiime/pe-demux_dada2_rep_seqs.qza'
    output:
        'data/qiime/us_taxonomy.qza'
    shell:
        '''
        qiime feature-classifier classify-sklearn \
            --i-classifier {input.classifier} \
            --i-reads {input.rep_seq} \
            --o-classification {output[0]}
        '''

rule visualize_our_taxonomy:
    input:
        'data/qiime/us_taxonomy.qza'
    output:
        'data/qiime/us_taxonomy.qzv'
    shell:
        'qiime metadata tabulate \
            --m-input-file {input[0]} \
            --o-visualization {output[0]}'

rule class:
    input:
        'data/qiime/us_taxonomy.qzv'

# Alpha rarefaction plotting
# need to use the pheno table for the stool samples
# here use pe-demux_dada2_filtered.qza cuz on the cluster only keeping the features in the insertion tree

rule visualize_alpha_rarefaction:
    input:
        cts='data/qiime/pe-demux_dada2_filtered.qza',
        tree='data/qiime/greengenes_insertion-tree.qza',
        meta='data/pheno/samples_pheno_67.tsv'
    output:
        'data/qiime/us_alpha-rarefaction.qzv'
    shell:
        '''
        qiime diversity alpha-rarefaction \
            --i-table {input.cts} \
            --i-phylogeny {input.tree} \
            --p-max-depth 4000 \
            --m-metadata-file {input.meta} \
            --o-visualization {output[0]}
        '''

 
# use the above visualization to decide the sampling depth for normalization in the core metrics step
# where does the curve start to level out?

rule core_metrics_phylogenetic:
    input:
        cts='data/qiime/pe-demux_dada2_filtered.qza',
        tree='data/qiime/greengenes_insertion-tree.qza',
        meta='data/pheno/samples_pheno_67.tsv',
        sampling_depth='1000'
    output:
        'data/qiime/core-metrics-results'
    shell:
        '''
        qiime diversity core-metrics-phylogenetic \
            --i-phylogeny {input.tree} \
            --i-table {input.cts} \
            --p-sampling-depth {input.sampling_depth} \
            --m-metadata-file {input.meta}  \
            --output-dir {output[0]}
        '''



rule rare:
    input:
        'data/qiime/core-metrics-results'



#########################################################################
# This section is for calculating beta diversity for our stool samples
# however you lump the stool samples together
########################################################################

# the diet data spans from the -10 to 41 relative to transplant, 
# so need to filter on the stool samples to include near to that period

# here I'm gonna use the samples I organized from the R script 13: stb_final_mean
# and to filter you can use a meta table and create a column to mark which samples to keep and which to remove

rule filter_stool_samples_close_to_diet:
    input:
        ALL_in_tree='data/finalized/pe-demux_dada2_filtered.qza',
        meta='data/finalized/stool/filter_stool_close_to_diet_meta.tsv'
    output:
        'data/finalized/stool/pe-demux_dada2_filtered_close_to_diet_data.qza'
    shell:
        '''
        qiime feature-table filter-samples \
            --i-table {input.ALL_in_tree} \
            --m-metadata-file {input.meta} \
            --p-where "[keep]='keep'" \
            --o-filtered-table {output[0]}
        '''

rule stool:
    input:
        'data/finalized/stool/pe-demux_dada2_filtered_close_to_diet_data.qza'
