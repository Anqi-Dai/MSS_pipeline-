model_fake_fruits <- brm( model_f,
data = meta_f,
warmup = 1000, iter = 3000,
prior = priors,
cores = ncores,
chains = 2,
seed = 123, sample_prior = T)
post_samples  <- read_csv('../data/109_div_model_fg_post_fake_fruits.csv')
post_coeff <- post_samples %>%
select(starts_with('b_fg')) %>%
gather('item', 'coeff') %>%
mutate(item = str_replace(item, 'b_fg_','')) %>%
mutate(fgrp1 = case_when(
item ==  'milk' ~ '1',
item == 'meat' ~ '2',
item ==  'egg' ~ '3',
item ==  'legume' ~ '4',
item == 'grain' ~ '5',
item == 'fruit' ~ '6',
item == 'veggie' ~ '7',
item ==  'oils' ~ '8',
item ==  'sweets' ~ '9',
item ==  'fakefruits' ~ 'F'
))  %>%
mutate(item = fct_reorder(item, coeff, .fun=median, .desc = F))
cross0 <- post_coeff %>%
group_by(item) %>%
summarise(q2.5 = quantile(coeff, probs = 0.025),
q97.5 = quantile(coeff, probs = 0.975)) %>%
mutate(Cross = if_else(q2.5 > 0 | q97.5 < 0, F, T))
div_post_f <- post_coeff %>%
left_join(cross0) %>%
ggplot(aes(x = coeff, y = item, col = Cross)) +
stat_pointinterval(.width = c(.66, .95)) +
geom_vline(xintercept = 0, col = 'black', linetype = 'dashed') +
labs(x = 'ln(diversity) change per 100g of food',
y = '',
title = 'Diversity') +
theme_classic() +
theme(legend.position = 'none') +
scale_color_manual(values = c("#EC0000", "gray40")) +
theme(axis.text=element_text(size=8),
axis.title=element_text(size=8),
aspect.ratio=1)
ggsave('../data/109_fake_fruits_main_model.jpg', plot = div_post_f)
ggsave('../data/109_fake_fruits_main_model.jpg', plot = div_post_f,
width = 170,
height = 60,
#height = 60,
units = c("mm"))
ggsave('../data/110_new_sweets_main_model.jpg', plot = div_post_2,
width = 170,
height = 60,
#height = 60,
units = c("mm"))
ggsave('../data/110_new_sweets_main_model.jpg', plot = div_post_2,
width =80,
height = 60,
#height = 60,
units = c("mm"))
ggsave('../data/109_fake_fruits_main_model.jpg', plot = div_post_f,
width = 80,
height = 60,
#height = 60,
units = c("mm"))
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(brms)
library(ggpubr)
library(tidybayes)
library(cowplot)
ncores <- parallel::detectCores()
dtb <- read_csv('../data/cleaned_diet_data/FINAL_97_with_code_all_foods_drt_with_EN_finalized.csv') %>%
mutate(Food_code = as.character(Food_code))
fruits_fake <- read_csv('../data/108_unique_fruits_PAAedit.csv') %>%
mutate(Food_code = as.character(Food_code)) %>%
filter(fruit_include == 'no')
dtbf <- dtb %>%
mutate(Food_code = if_else(Food_code %in% fruits_fake$Food_code,
str_replace(Food_code, '^6','F'),
Food_code))
fgrps_df <- dtbf %>%
select(mrn, fdrt, dehydrated_weight, Food_code) %>%
mutate(fgrp1 = str_sub(Food_code, 1, 1))
total_per_group <- fgrps_df %>%
group_by(mrn, fdrt, fgrp1) %>%
summarise(grp_tol = sum(dehydrated_weight)) %>%
mutate(fg1_name = case_when(
fgrp1 == '1' ~ 'fg_milk',
fgrp1 == '2' ~ 'fg_meat',
fgrp1 == '3' ~ 'fg_egg',
fgrp1 == '4' ~ 'fg_legume',
fgrp1 == '5' ~ 'fg_grain',
fgrp1 == '6' ~ 'fg_fruit',
fgrp1 == '7' ~ 'fg_veggie',
fgrp1 == '8' ~ 'fg_oils',
fgrp1 == '9' ~ 'fg_sweets',
fgrp1 == 'F' ~ 'fg_fakefruits'
))
meta <- read_csv('../data/cleaned_stool/all_samples_meta_p2d_fg9_updated.csv')
stb_pair <- meta %>%
select(mrn, sdrt) %>%
transmute(mrn = mrn,
p1d = sdrt-1,
p2d = sdrt-2)
mean_p2d_diet <-  function(mrn_, p1d_, p2d_){
df = total_per_group %>%
filter(mrn == mrn_) %>%
filter(fdrt %in% c(p1d_, p2d_  )) %>%
group_by(fg1_name) %>%
summarise(ave_fg = sum(grp_tol)/2)
return(df)
}
mean_p2d_df <- pmap(stb_pair, function(mrn, p1d, p2d){
mean_p2d_diet(mrn, p1d, p2d)
}) %>%
set_names(meta %>% pull(sampleid)) %>%
bind_rows(.id = 'sampleid') %>%
spread(key = 'fg1_name', value = 'ave_fg', fill = 0) %>%
inner_join(meta %>%
select(-starts_with('fg')), by = "sampleid")
meta_f <- mean_p2d_df %>%
mutate(timebin = cut_width(sdrt, 7, boundary=0, closed = 'left')) %>%
mutate(intensity = factor(intensity, levels = c('nonablative','reduced','ablative'))) %>%
mutate(mrn = factor(mrn)) %>%
mutate(fg_egg = fg_egg/100,
fg_fruit = fg_fruit/100,
fg_grain = fg_grain/100,
fg_legume = fg_legume/100,
fg_meat = fg_meat/100,
fg_milk = fg_milk/100,
fg_oils = fg_oils/100,
fg_sweets = fg_sweets/100,
fg_veggie = fg_veggie/100,
fg_fakefruits = fg_fakefruits/100)
mean_p2d_df <- pmap(stb_pair, function(mrn, p1d, p2d){
mean_p2d_diet(mrn, p1d, p2d)
}) %>%
set_names(meta %>% pull(sampleid)) %>%
bind_rows(.id = 'sampleid') %>%
spread(key = 'fg1_name', value = 'ave_fg', fill = 0) %>%
inner_join(meta %>%
select(-starts_with('fg')), by = "sampleid") %>%
mutate(timebin = cut_width(sdrt, 7, boundary=0, closed = 'left'))
View(mean_p2d_df)
mean_p2d_df
#  could you plot a histogram of the fake fruit column, and also a boxplot of "fake fruits" on the y axis and "time bin" on the x axis?
mean_p2d_df %>%
gghistogram(x = 'fg_fakefruits')
#  could you plot a histogram of the fake fruit column, and also a boxplot of "fake fruits" on the y axis and "time bin" on the x axis?
mean_p2d_df %>%
gghistogram(x = 'fg_fakefruits',
xlab = 'average fake fruits gram intake in the previous two days')
mean_p2d_df
mean_p2d_df %>%
ggboxplot(x = 'timebin', y = 'fg_fakefruits')
mean_p2d_df %>%
ggboxplot(x = 'timebin', y = 'fg_fakefruits') +
scale_y_sqrt()
knitr::opts_chunk$set(echo = TRUE)
chen <- read_csv('../data/chen.csv')
get_table_from_database('asv_alpha_diversity_ag')
library(tidyverse)
library(vdbR)
connect_database()
chen <- read_csv('../data/chen.csv')
get_table_from_database('asv_alpha_diversity_ag')
location <- chen %>%
inner_join(asv_alpha_diversity_ag %>%
distinct(sampleid, .keep_all = T) %>%
rename(SampleID = sampleid))
missing <- chen %>%
filter(! SampleID %in% asv_alpha_diversity_ag$sampleid)
found <- location %>%
select(oligos_id, path_pool) %>%
mutate(R1 = str_glue('{oligos_id}_R1.fastq.gz'),
R2 = str_glue('{oligos_id}_R2.fastq.gz')) %>%
mutate(p1 = str_glue('{path_pool}/{R1}'),
p2 = str_glue('{path_pool}/{R2}')) %>%
select(p1, p2) %>%
gather() %>%
mutate(cmd = str_glue('rsync --progress --partial -avz daia1@lilac.mskcc.org:{value} .')) %>%
select(cmd) %>%
write_csv('/Volumes/castoricenter/Chen/raw_amplicon_found/dl_chen12729.sh', col_names = F)
found <- location %>%
select(oligos_id, path_pool) %>%
mutate(R1 = str_glue('{oligos_id}_R1.fastq.gz'),
R2 = str_glue('{oligos_id}_R2.fastq.gz')) %>%
mutate(p1 = str_glue('{path_pool}/{R1}'),
p2 = str_glue('{path_pool}/{R2}')) %>%
select(p1, p2)
View(found)
found <- location %>%
select(oligos_id, path_pool) %>%
mutate(R1 = str_glue('{oligos_id}_R1.fastq.gz'),
R2 = str_glue('{oligos_id}_R2.fastq.gz')) %>%
mutate(p1 = str_glue('{path_pool}/{R1}'),
p2 = str_glue('{path_pool}/{R2}')) %>%
select(p1, p2) %>%
gather()
found %>%
write_csv('../data/path_for_chen_samples.csv')
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(vdbR)
connect_database()
get_table_from_database('asv_alpha_diversity_ag')
get_table_from_database('shotgun_lookup_ad')
dat <- asv_alpha_diversity_ag %>%
distinct(oligos_id) %>%
mutate(poolid = str_extract(oligos_id, 'pool.+$')) %>%
distinct(poolid) %>%
filter(str_detect(poolid, 'pool835|pool935|pool940|pool1042|pool1048|pool1050|pool1064|pool1109|pool1117|pool1121'))
#pool1109
asv_alpha_diversity_ag %>%
write_csv('../data/asv_alpha_diversity_ag.csv')
# total: 2678
duke <- read_csv('../data/duke_samples_for_angel_02-22-2022 (1).csv') %>%
rename(oligos_id = oligoid)
# already 1769
already <- duke %>%
inner_join(asv_alpha_diversity_ag, by = 'oligos_id') %>%
distinct(oligos_id, .keep_all = T)
already %>%
select(oligos_id, path_pool ) %>%
write_csv('../data/duke/already_1769_path.csv')
# missing
missing <- duke %>%
filter(!oligos_id %in% asv_alpha_diversity_ag$oligos_id)
find <- missing %>%
filter(submitted_for_sequencing == 'yes') %>%
select(sampleid, sampleid_clean, oligos_id, notes , experiment)  %>%
mutate(sid = str_replace_all(oligos_id, '-|/|_','\\.'))
find %>%
count(notes)
two <- asv_alpha_diversity_ag %>%
filter(str_detect(path_pool, 'pool1096\\+1097|pool1100')) %>%
select(oligos_id, path_pool) %>%
distinct(oligos_id, .keep_all = T)
length(intersect(two$sid, find$sid))
setdiff(two$sid, find$sid)
two %>%
write_csv('../data/duke/two_pools_90_path.csv')
setdiff( find$sid, two$sid)
# the 228 that don't know what the pool or where the samples are
where <- find %>%
filter(!sid %in% two$sid)
where %>%
write_csv('../data/duke/where_the_228.csv')
# reply from John
reply <- read_csv('~/Downloads/where_the_228_JS_03-21-2022.csv') %>%
distinct(sid, .keep_all = T) %>%
distinct(js_comment)
length(intersect(reply$sid, asv_alpha_diversity_ag$sampleid))
# after running the last pool 11037
reply %>%
filter(str_detect(js_comment, '11037'))
# assemble the file path that need to be copied to the duke folder in amplicon
current <- bind_rows(
two %>%
mutate(R1 = str_glue('{path_pool}/{oligos_id}_R1.fastq.gz'),
R2 = str_glue('{path_pool}/{oligos_id}_R2.fastq.gz')),
already %>%
mutate(R1 = str_glue('{path_pool}/{oligos_id}_R1.fastq.gz'),
R2 = str_glue('{path_pool}/{oligos_id}_R2.fastq.gz'))
) %>%
filter(!str_detect(oligos_id, '^blank'))
current %>%
select(R1, R2) %>%
gather() %>%
mutate(cmd = str_glue('cp {value} /home/daia1/my_workdir/samples/amplicon/duke')) %>%
select(cmd) %>%
write_csv('../data/cp_duke_1851.sh',col_names = F)
View(current)
View(two)
View(already)
View(asv_alpha_diversity_ag)
asv_alpha_diversity_ag
# find out the sampleids of those 1851 samples
alpha_all <- asv_alpha_diversity_ag %>%
distinct(sampleid, oligos_id, simpson_reciprocal, shannon)
alpha_all
alpha <- alpha_all %>%
filter(oligos_id %in% current$oligos_id)
test <- get_counts_subset(c('X759A'))
test <- get_counts_subset(c('X759A'))
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(vdbR)
connect_database()
get_table_from_database('asv_alpha_diversity_ag')
get_table_from_database('shotgun_lookup_ad')
dat <- asv_alpha_diversity_ag %>%
distinct(oligos_id) %>%
mutate(poolid = str_extract(oligos_id, 'pool.+$')) %>%
distinct(poolid) %>%
filter(str_detect(poolid, 'pool835|pool935|pool940|pool1042|pool1048|pool1050|pool1064|pool1109|pool1117|pool1121'))
#pool1109
asv_alpha_diversity_ag %>%
write_csv('../data/asv_alpha_diversity_ag.csv')
test <- get_counts_subset(c('X759A'))
# find out the sampleids of those 1851 samples
alpha_all <- asv_alpha_diversity_ag %>%
distinct(sampleid, oligos_id, simpson_reciprocal, shannon)
alpha <- alpha_all %>%
filter(oligos_id %in% current$oligos_id)
test <- get_counts_subset('X759A')
View(alpha_all)
test <- get_counts_subset('01.BS.17')
View(test)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(vdbR)
connect_database()
get_table_from_database('asv_alpha_diversity_ag')
get_table_from_database('shotgun_lookup_ad')
dat <- asv_alpha_diversity_ag %>%
distinct(oligos_id) %>%
mutate(poolid = str_extract(oligos_id, 'pool.+$')) %>%
distinct(poolid) %>%
filter(str_detect(poolid, 'pool835|pool935|pool940|pool1042|pool1048|pool1050|pool1064|pool1109|pool1117|pool1121'))
#pool1109
asv_alpha_diversity_ag %>%
write_csv('../data/asv_alpha_diversity_ag.csv')
# total: 2678
duke <- read_csv('../data/duke_samples_for_angel_02-22-2022 (1).csv') %>%
rename(oligos_id = oligoid)
# already 1769
already <- duke %>%
inner_join(asv_alpha_diversity_ag, by = 'oligos_id') %>%
distinct(oligos_id, .keep_all = T)
already %>%
select(oligos_id, path_pool ) %>%
write_csv('../data/duke/already_1769_path.csv')
# missing
missing <- duke %>%
filter(!oligos_id %in% asv_alpha_diversity_ag$oligos_id)
find <- missing %>%
filter(submitted_for_sequencing == 'yes') %>%
select(sampleid, sampleid_clean, oligos_id, notes , experiment)  %>%
mutate(sid = str_replace_all(oligos_id, '-|/|_','\\.'))
find %>%
count(notes)
two <- asv_alpha_diversity_ag %>%
filter(str_detect(path_pool, 'pool1096\\+1097|pool1100')) %>%
select(oligos_id, path_pool) %>%
distinct(oligos_id, .keep_all = T)
length(intersect(two$sid, find$sid))
setdiff(two$sid, find$sid)
two %>%
write_csv('../data/duke/two_pools_90_path.csv')
setdiff( find$sid, two$sid)
# the 228 that don't know what the pool or where the samples are
where <- find %>%
filter(!sid %in% two$sid)
where %>%
write_csv('../data/duke/where_the_228.csv')
# reply from John
reply <- read_csv('~/Downloads/where_the_228_JS_03-21-2022.csv') %>%
distinct(sid, .keep_all = T) %>%
distinct(js_comment)
length(intersect(reply$sid, asv_alpha_diversity_ag$sampleid))
# after running the last pool 11037
reply %>%
filter(str_detect(js_comment, '11037'))
# assemble the file path that need to be copied to the duke folder in amplicon
current <- bind_rows(
two %>%
mutate(R1 = str_glue('{path_pool}/{oligos_id}_R1.fastq.gz'),
R2 = str_glue('{path_pool}/{oligos_id}_R2.fastq.gz')),
already %>%
mutate(R1 = str_glue('{path_pool}/{oligos_id}_R1.fastq.gz'),
R2 = str_glue('{path_pool}/{oligos_id}_R2.fastq.gz'))
) %>%
filter(!str_detect(oligos_id, '^blank'))
current %>%
select(R1, R2) %>%
gather() %>%
mutate(cmd = str_glue('cp {value} /home/daia1/my_workdir/samples/amplicon/duke')) %>%
select(cmd) %>%
write_csv('../data/cp_duke_1851.sh',col_names = F)
alpha_all <- asv_alpha_diversity_ag %>%
distinct(sampleid, oligos_id, simpson_reciprocal, shannon)
alpha <- alpha_all %>%
filter(oligos_id %in% current$oligos_id)
View(alpha)
all.equal(alpha$sampleid, alpha$oligos_id)
which(alpha$sampleid!= alpha$oligos_id)
alpha
alpha %>%
filter(sampleid!=oligos_id)
test <- get_counts_subset(c('22331.D7.97883'))
View(test)
alpha %>%
filter(sampleid!=oligos_id)
# the oligos ID are correct, the sampleid need some cleaning
clean_sampleid <- alpha %>%
mutate(sampleid = if_else(sampleid != oligos_id, str_replace(oligos_id, '\\.\\.pool.+$','')))
# the oligos ID are correct, the sampleid need some cleaning
clean_sampleid <- alpha %>%
mutate(sampleid = if_else(sampleid != oligos_id, str_replace(oligos_id, '\\.\\.pool.+$',''), sampleid))
clean_sampleid %>%
filter(sampleid!=oligos_id)
sum(test$count)
cts <- get_counts_subset(clean_sampleid$sampleid) %>%
select(asv_key:count_total, count_relative)
View(cts)
cts %>% distinct(sampleid)
taxa <- asv_annotation_blast_ag %>%
filter(asv_key %in% cts$asv_key) %>%
select(asv_key:blast_pass)
get_table_from_database('asv_annotation_blast_ag')
taxa <- asv_annotation_blast_ag %>%
filter(asv_key %in% cts$asv_key) %>%
select(asv_key:blast_pass)
# find out the sampleids of those 1851 samples
alpha_all <- asv_alpha_diversity_ag %>%
distinct(sampleid, oligos_id, simpson_reciprocal, shannon)
alpha <- alpha_all %>%
filter(oligos_id %in% current$oligos_id)
# the oligos ID are correct, the sampleid need some cleaning
clean_sampleid <- alpha %>%
mutate(sampleid = if_else(sampleid != oligos_id, str_replace(oligos_id, '\\.\\.pool.+$',''), sampleid))
cts <- get_counts_subset(clean_sampleid$sampleid) %>%
select(asv_key:count_total, count_relative)
taxa <- asv_annotation_blast_ag %>%
filter(asv_key %in% cts$asv_key) %>%
select(asv_key:blast_pass)
list(alpha = alpha,
counts = cts,
taxa = taxa) %>%
imap(function(.x, .y){
write_csv(.x, str_glue('../data/Duke_ASV_{.y}.csv'))
})
View(alpha)
View(already)
View(two)
1769+90
already
# for the table that match our sampleids to their sampleids:
# first figure out what exactly is their sampleid
see <- already %>%
filter(!str_detect(oligos_id, '^blank'))
View(see)
see
# for the table that match our sampleids to their sampleids:
# first figure out what exactly is their sampleid
see <- already %>%
filter(!str_detect(oligos_id, '^blank')) %>%
select(oligos_id:timepoint_int)
see
# for the table that match our sampleids to their sampleids:
# first figure out what exactly is their sampleid
see <- already %>%
filter(!str_detect(oligos_id, '^blank')) %>%
select(oligos_id:timepoint_int) %>%
mutate(dukeid = sampleid.x)
# for the table that match our sampleids to their sampleids:
# first figure out what exactly is their sampleid
see <- already %>%
filter(!str_detect(oligos_id, '^blank')) %>%
select(oligos_id:timepoint_int) %>%
rename(dukeid = sampleid.x)
see %>%
write_csv('../data/what_is_duke_sampleid_1761.csv')
View(missing)
View(missing)
two <- asv_alpha_diversity_ag %>%
filter(str_detect(path_pool, 'pool1096\\+1097|pool1100')) %>%
select(oligos_id, path_pool) %>%
distinct(oligos_id, .keep_all = T)
two <- asv_alpha_diversity_ag %>%
filter(str_detect(path_pool, 'pool1096\\+1097|pool1100'))
two <- asv_alpha_diversity_ag %>%
filter(str_detect(path_pool, 'pool1096\\+1097|pool1100')) %>%
#select(oligos_id, path_pool) %>%
distinct(oligos_id, .keep_all = T)
View(find)
# the ones that need re-sequencing
again <- missing %>%
filter(notes == 'April 2021 shipment Box 53')
View(again)
# the ones that need re-sequencing
again <- missing %>%
filter(notes == '	July 2021 box')
# the ones that need re-sequencing
again <- missing %>%
filter(notes == 'July 2021 box')
909-90+8
2678 - 1851
two <- asv_alpha_diversity_ag %>%
filter(str_detect(path_pool, 'pool1096\\+1097|pool1100'))
View(two)
two <- asv_alpha_diversity_ag %>%
filter(str_detect(path_pool, 'pool1096\\+1097|pool1100')) %>%
#select(oligos_id, path_pool) %>%
distinct(oligos_id, .keep_all = T)
View(missing)
two
# the ones that need re-sequencing missing909 - two 90 + blank 8 = 827
# the question is the two pools that Emily sequenced the latest
two_cleaned <- two %>%
mutate(sampleid_clean = str_replace_all(sampleid, '\\.','-'))
View(two_cleaned)
length(intersect(two_cleaned$sampleid_clean, missing$sampleid_clean))
two_cleaned$sampleid_clean
missing %>%
filter(str_detect(notes, 'Emily')) %>% pull(sampleid_clean)
two_cleaned <- two %>%
mutate(sampleid_clean = str_replace_all(sampleid, '\\.','_'))
length(intersect(two_cleaned$sampleid_clean, missing$sampleid_clean))
setdiff(two_cleaned$sampleid_clean, missing$sampleid_clean)
