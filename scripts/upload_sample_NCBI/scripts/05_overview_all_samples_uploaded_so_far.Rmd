---
title: "submitted samples catalog"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(vdbR)
connect_database()
get_table_from_database('asv_alpha_diversity_ag')
```

```{r}
# downloaded today 02-20-2022 biosamples
# each download max captures 10000 samples
first <- read_tsv('../data/table_download_1.tsv')
second <- read_tsv('../data/table_download_2.tsv')
third <- read_tsv('../data/table_download_3.tsv')
total <- bind_rows(first, second, third)

biopro <- read_tsv('../data/table_download_bioproject.tsv')
# are there any duplicated submission
unique_ones <- total %>% 
  distinct(BioSample.name) %>% 
  nrow

nrow(total) - unique_ones
# lots of duplicated submissions

# look at Joao submission
joao <- read_csv('~/Downloads/tblASVsamples.csv')

length(intersect(joao$SampleID, total$BioSample.name))

length(intersect(joao$BioProject, biopro$Accession))


```

```{r}
# look at the uploaded SRA files
sra <- bind_rows(read_tsv('../data/sra1.tsv'),
                 read_tsv('../data/sra2.tsv'),
                 read_tsv('../data/sra3.tsv'),
                 read_tsv('../data/sra4.tsv'),
                 read_tsv('../data/sra5.tsv'))

length(intersect(joao$Accession, sra$Accession)) 

# are there any shotgun samples
shotgun_already <- sra %>% 
  filter(!str_detect(SRA.filename, 'pool')) %>% 
  filter(!str_detect(SRA.filename, 'tp|aes'))  %>% 
  filter(str_detect(SRA.filename, 'nohumanreads')) %>% 
  rename(sampleid = Title)

all_shotgun <- sra %>% 
  filter(!str_detect(SRA.filename, 'pool')) %>% 
  filter(!str_detect(SRA.filename, 'tp|aes'))
# 16s sra files 
nrow(sra) - nrow(all_shotgun) 
``` 

```{r}
# look at what samples in marina's need to be uploaded  16s
marina <- read_csv('../data/marina/Doris_7_30_21_FINAL_unique_sampleids_16S.csv')
length(intersect(marina$sampleid, total$BioSample.name))
# the biosamples all existed
# I need to find the sra accession for the 16s in these samples 

# the samples that are very likely qualified 16s sra files
cleaned_sra <- sra %>% 
  mutate(sampleid = str_extract(SRA.filename, '^.+,'),
         sampleid = str_replace(sampleid, 'pool..._R1.trimmed.fastq_','')) %>% 
  filter(!str_detect(SRA.filename, 'fastq$')) %>% 
  select(SRA.filename, sampleid) %>% 
  filter(!str_detect(SRA.filename, '^reads1')) %>% 
  mutate(sampleid = str_replace(sampleid, '_R1.fastq.gz,','')) %>% 
  filter(!str_detect(SRA.filename, '_R1.trimmed.fastq')) %>% 
  filter(!str_detect(SRA.filename, 'aes|tp|nohumanreads.')) %>% 
  filter(str_detect(sampleid, 'pool')) %>% 
  mutate(sampleid = str_replace(sampleid, '\\.\\.pool.+$',''))

length(intersect(marina$sampleid, cleaned_sra$sampleid))
find <- setdiff(marina$sampleid, cleaned_sra$sampleid)

res <- asv_alpha_diversity_ag  %>% 
  filter(sampleid %in% find)
# the above is the samples needed to be uploaded. the dada2 version 

# find the biosample id of those
biosamples <- total %>% 
  filter(BioSample.name %in% res$sampleid) %>% 
  arrange(BioSample.name, desc(`Release Date`)) %>% 
  distinct(BioSample.name, .keep_all = T) %>% 
  select(Accession, BioSample.name) %>% 
  rename(sampleid = BioSample.name) %>% 
  inner_join(res) %>% 
  mutate(R1 = str_glue('{oligos_id}_R1.fastq.gz'),
         R2 = str_glue('{oligos_id}_R2.fastq.gz')) %>% 
  mutate(p1 = str_glue('{path_pool}/{R1}'),
         p2 = str_glue('{path_pool}/{R2}'))
  

 biosamples %>% 
   select(p1, p2) %>% 
   gather() %>% 
   mutate(cmd = str_glue('scp daia1@lilac.mskcc.org:{value} .')) %>% 
   select(cmd) %>% 
   write_csv('../data/dl_m7.sh', col_names = F)
 
 
 biosamples %>% 
   select(Accession, sampleid, R1, R2) %>% 
   write_csv('../data/marina/sra_meta.csv')
 
# Marina's done!!!!!!!
```


```{r}
# to make a table with the sampleid and accession
# for marina 16s
already_m <- cleaned_sra %>% 
  inner_join(marina) %>% 
  distinct(sampleid, .keep_all = T) %>% 
  inner_join(sra) %>% 
  distinct(sampleid, .keep_all = T) %>% 
  select(Accession, sampleid) 



# the newly submitted 7
new7 <- read_tsv('../data/marina/metadata-11133079-sra-7.tsv') %>% 
  select(Accession = accession, sampleid = library_ID)

all_16s <- bind_rows(
  new7, already_m
)


all_16s %>% 
  write_csv('../data/marina/all_16s_sra_acc_1303.csv')
  
```


```{r}
# marina shotgun samples
ms <- read_csv('../data/marina/Doris_7_30_21_FINAL_unique_sampleids_SHOTGUN.csv')

# all of them need to be uploaded the preprocessed version

```








# Hana

```{r}
# now look at Hana's
h <- read_csv('../data/hana/All_sampleids_MAITs.csv')
length(intersect(h$sampleid, total$BioSample.name))


# these are the ones that don't have biosamples !!!!!!!!!!!1
newsa <- setdiff(h$sampleid, total$BioSample.name)
hfiles <- asv_alpha_diversity_ag %>% 
  filter(sampleid %in% newsa) %>% 
  distinct(sampleid, .keep_all = T) %>% 
  mutate(R1 = str_glue('{oligos_id}_R1.fastq.gz'),
         R2 = str_glue('{oligos_id}_R2.fastq.gz')) %>% 
  mutate(p1 = str_glue('{path_pool}/{R1}'),
         p2 = str_glue('{path_pool}/{R2}'))

hfiles %>% 
   select(p1, p2) %>% 
   gather() %>% 
   mutate(cmd = str_glue('scp daia1@lilac.mskcc.org:{value} .')) %>% 
   select(cmd) %>% 
   write_csv('../data/dl_h14.sh', col_names = F)

h14 <- h %>% 
  filter(sampleid %in% newsa) %>% 
  mutate(pid = str_extract(sampleid, '\\d\\d\\d\\d'))

# now write out the biosample att file for uploading to the website
h_att <- tibble(
  Sample_name = h14$sampleid,
  Organism = 'human gut metagenome',
  host = 'Homo sapiens',
  isolation_source = 'stool',
  collection_date = 'not applicable',
  geo_loc_name = 'USA: New York',
  lat_lon = '40.7641 N 73.9568 W',
  patient_id = h14$pid,
  DayRelativeToNearestHCT =  h14$sample_day
) 

h_att %>% 
  write_tsv('../data/hana/h_att.tsv')
```

```{r}
sra_h <- tibble(
  sample_name = hfiles$sampleid,
  library_ID = hfiles$sampleid,
  title = 'Stool sample of allo-HCT patient',
  library_strategy = 'amplicon',
  library_source = 'GENOMIC',
  library_selection = 'PCR',
  library_layout ='paired',
  platform= 'ILLUMINA',
  instrument_model= 'Illumina MiSeq',
  design_description='PCR amplification of 16S V4-V5 regions; Bead-beating, phenol chloroform DNA extraction',
  filetype= 'fastq',
  filename=hfiles$R1,
  filename2=hfiles$R2
)
sra_h %>% 
  write_tsv('../data/hana/h_sra.tsv')
```

```{r}
# the samples we have the srr accession already
# correct fastq files 
h_already <- cleaned_sra %>% 
  distinct(sampleid, .keep_all = T) %>% 
  filter(sampleid %in% h$sampleid) %>% 
  inner_join(sra %>% 
               distinct(SRA.filename, .keep_all = T)) %>% 
  select(sampleid, Accession)

h_already %>% 
  write_csv('../data/hana/acc1_568.csv')


# the ones that we need to upload the corrct dada2 results fastqs
length(setdiff(h$sampleid, cleaned_sra$sampleid))

# the path of the files 
fastq2 <- asv_alpha_diversity_ag %>% 
  filter(sampleid %in% setdiff(h$sampleid, cleaned_sra$sampleid)) %>% 
  distinct(sampleid, .keep_all = T) %>% 
  mutate(R1 = str_glue('{oligos_id}_R1.fastq.gz'),
         R2 = str_glue('{oligos_id}_R2.fastq.gz')) %>% 
  mutate(p1 = str_glue('{path_pool}/{R1}'),
         p2 = str_glue('{path_pool}/{R2}'))

fastq2 %>% 
   select(p1, p2) %>% 
   gather() %>% 
   mutate(cmd = str_glue('scp daia1@lilac.mskcc.org:{value} .')) %>% 
   select(cmd) %>% 
   write_csv('../data/dl_h157.sh', col_names = F)



# Hana: total 725.  new biosample+sra : 14  alrady:568 
# the biosample acc of these samples (143)
h2 <- total %>% 
  filter(BioSample.name %in% fastq2$sampleid)  %>% 
  distinct(BioSample.name, .keep_all = T) %>% 
  rename(sampleid = BioSample.name) %>% 
  inner_join(fastq2)


sra_h2 <- tibble(
  biosample_accession = h2$Accession,
  library_ID = h2$sampleid,
  title = 'Stool sample of allo-HCT patient',
  library_strategy = 'amplicon',
  library_source = 'GENOMIC',
  library_selection = 'PCR',
  library_layout ='paired',
  platform= 'ILLUMINA',
  instrument_model= 'Illumina MiSeq',
  design_description='PCR amplification of 16S V4-V5 regions; Bead-beating, phenol chloroform DNA extraction',
  filetype= 'fastq',
  filename=h2$R1,
  filename2=h2$R2
)
sra_h2 %>% 
  write_tsv('../data/hana/sra_143.tsv')
```

```{r}
# the files that I downloaded from lilac
fns <- tibble(fn = list.files('../data/hana/fastqs/')) %>% 
  separate(fn , into = c('sampleid','pair'), sep = '_R')

missing <- fns %>% 
  count(sampleid) %>% 
  arrange(n) %>% 
  filter(n == 1)

fns %>% 
  filter(sampleid %in% missing$sampleid)

fastq2 %>% 
  filter(oligos_id %in% missing$sampleid) %>% 
  select(p2)%>% 
   mutate(cmd = str_glue('scp daia1@lilac.mskcc.org:{p2} .')) %>% 
   select(cmd) %>% 
   write_csv('../data/dl_h5_2.sh', col_names = F)
```

```{r}
# the 14 that I uploaded earlier 
# now the sra accession returned by ncbi
h14 <- read_tsv('../data/hana/hana_14_ncbi.tsv') %>% 
  select( sampleid = sample_name, Accession = accession)

h14 %>% write_csv('../data/hana/acc2_14.csv')
```



```{r}
# tables from these
dir.create('../data/save')
sra %>% 
  write_csv('../data/save/all_sra_table_20220226.csv')

cleaned_sra %>% 
  write_csv('../data/save/human_cleaned_sra_20220226.csv')

total %>% 
  write_csv('../data/save/all_biosample_table_20220226.csv')
```

