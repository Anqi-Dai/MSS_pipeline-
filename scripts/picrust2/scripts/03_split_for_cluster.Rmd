---
title: "Split all the 16 samples into batches and try to get it to run on the cluster"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggpubr)
library(cowplot)
```

```{r}
source('~/db.R')
#load the big db table
CTS <- get_data_from_query_OTU(0,'asv_counts_ag')
SEQS <- get_data_from_query_OTU(0,'asv_sequences_ag')
```
 


Decide on the threshold of filtering the samples by total number of count

```{r}
total_cnt <- CTS %>% 
  distinct(sampleid, count_total)

total_cnt %>% 
  gghistogram('count_total', title = 'Distribution of count total per sample')

# what percentile is total count == 500
# keeping 98% of all samples
nrow(total_cnt[total_cnt$count_total >= 500])/nrow(total_cnt)*100


# keeping 95% of all samples
nrow(total_cnt[total_cnt$count_total >= 2000])/nrow(total_cnt)*100


# CURRENTLY DECIDE TO KEEP THE THRESHOLD TO BE 500
```

```{r filter_sample_total_count}
rm_samples <- total_cnt %>% 
  filter(count_total < 500) %>% 
  pull(sampleid) 
  
CTS_fil <- CTS %>% 
  filter(!sampleid %in% rm_samples)


#See how many samples total that we have 16s asv counts now
n_samples <- CTS_fil %>% 
  dplyr::count(sampleid, count_total) %>% 
  arrange(sampleid, desc(count_total)) %>% 
  # remove the duplicated samples here
  distinct(sampleid, .keep_all = T)
```

```{r}
# see the distribution of the number of asv per sample
n_samples %>% 
  gghistogram('n', bins = 30, xlab = 'Number of asv per sample',
              title = 'distribution for samples that have count >= 500')

# divide the samples into 2 groups on median asv number per sample
med_asv_num <- quantile(n_samples$n, 0.5)


combi_low <- n_samples %>% 
  mutate(combi = str_glue('{sampleid}_{count_total}')) %>% 
  filter(n < med_asv_num) %>% 
  pull(combi)


combi_high <- n_samples %>% 
  mutate(combi = str_glue('{sampleid}_{count_total}')) %>% 
  filter(n >= med_asv_num) %>% 
  pull(combi)

CTS_fil_low <- CTS_fil %>% 
  mutate(combi = str_glue('{sampleid}_{count_total}')) %>% 
  filter(combi %in% combi_low)


CTS_fil_high <- CTS_fil %>% 
  mutate(combi = str_glue('{sampleid}_{count_total}')) %>% 
  filter(combi %in% combi_high)
```
 
Split them into 100 samples per batch and play around with the nonzero threshold

```{r}
# total number of samples in each group and then split
splitted_low <- CTS_fil_low %>% 
  distinct(sampleid) %>% 
  split(cut_width(1:nrow(.), 100, boundary=0))

splitted_high <- CTS_fil_high %>% 
  distinct(sampleid) %>% 
  split(cut_width(1:nrow(.), 100, boundary=0))

# a function with input a df with sampleid, and then output the spreaded counts matrix
spread_100 <- function(DF_group, df){
  cts <- DF_group %>% 
    filter(sampleid %in% df$sampleid) %>% 
    select(asv_key, sampleid, count) %>% 
    spread(key = 'sampleid' , value = 'count', fill = 0)
  return(cts)
}

# to find the number of rows in the filtered count matrix
fil_cts_nrow <- function(spread_df, thre){
   cts_mat = spread_df %>% 
        column_to_rownames('asv_key') %>% 
        as.matrix()
      # find the singetons
    num_zero_thre = floor(ncol(cts_mat) * thre)
    cts_mat_fil = cts_mat[rowSums(cts_mat == 0) <= num_zero_thre, ]
    cts_mat_fil_nrow = cts_mat_fil %>% 
      as.data.frame() %>% 
      rownames_to_column('asv_key') %>% 
      nrow()
    return(cts_mat_fil_nrow)
}
```


```{r}
# try on the low group first
spread_list <- list()
for(i in 1:length(splitted_low)){
  spread_list[[i]] <- spread_100(CTS_fil_low, splitted_low[[i]])
}
```

```{r}
# investigate the kept number of asvs after filtering
thre <- seq(0.960, 0.995, 0.005)

# apply on all the df in the low group
low_fil_num <- spread_list %>% 
  map_dfr(function(df){ thre %>% 
          set_names(thre) %>% 
          map(~ fil_cts_nrow(df, .))})

# the original number of rows in each df
df_nrow <- spread_list %>% 
  set_names(seq(1:length(spread_list))) %>% 
  map_dfr(function(df){ return(nrow(df))}) %>% 
  gather('id', 'nrow') %>% 
  select(nrow)

low_fil_compare <- bind_cols(low_fil_num,df_nrow )
  
# convert the absolute number to a percentage
low_fil_perc <- low_fil_compare %>% 
  gather('thre', 'fil_nrow', names(.)[1]:names(.)[ncol(.)-1]) %>% 
  mutate(fil_nrow_perc = round(fil_nrow/nrow, 2))
```

```{r}
# the ditribution of the fraction of kept asv numbers
frac <- low_fil_perc %>% 
  ggboxplot('thre', 'fil_nrow_perc', title = 'All the subsets and the fraction',
            xlab = 'Filtering threshold', ylab = 'Fraction of number of rows left after filtering', add = 'jitter') +
  theme_bw()


# the absolute number
abs <- low_fil_perc %>% 
  ggboxplot('thre', 'fil_nrow', title = 'All the subsets and the absolute number',
            xlab = 'Filtering threshold', ylab = 'Absolute number of rows left after filtering', add = 'jitter') +
  theme_bw()

g <- plot_grid(frac, abs,
  nrow = 2,
  align = 'hv',
  axis = 'b')  +
  ggsave('../figs/frac_abs.jpg', width = 7, height = 7, dpi = 300)
 
```

DECIDED TO USE THE THRESHOLD OF 98%, remove the singletons

```{r}
return_filtered_count <- function(spread_df) {
     cts_mat = spread_df %>% 
        column_to_rownames('asv_key') %>% 
        as.matrix()
      # find the singetons
    num_zero_thre = floor(ncol(cts_mat) * 0.98)
    cts_mat_fil = cts_mat[rowSums(cts_mat == 0) <= num_zero_thre, ]
    cts_mat_fil = cts_mat_fil %>% 
      as.data.frame() %>% 
      rownames_to_column('asv_key') 
    return(cts_mat_fil)
}

spread_low <- list()
for(i in 1:length(splitted_low)){
  spread_low[[i]] <- spread_100(CTS_fil_low, splitted_low[[i]])
}

spread_high <- list()
for(i in 1:length(splitted_high)){
  spread_high[[i]] <- spread_100(CTS_fil_high, splitted_high[[i]])
}

spread_all <- c(spread_low, spread_high)


filtered_list <- spread_all %>% 
  map(~ return_filtered_count(.))
```

```{r}
# make a list of the asv sequence fasta file for each of the filtered count matrix
library(seqinr)

seqs_list <- list()
for(i in 1: length(filtered_list)){
  seqs_list[[i]]<- SEQS %>% 
    filter(asv_key %in% filtered_list[[i]]$asv_key)
}
```


```{r}
for ( i in 1:length(filtered_list)){
  filtered_list[[i]] %>% 
    write_tsv(str_glue('../data/splitted_100/filtered_counts_{i}.tsv'))
  
  seqs = seqs_list[[i]]
  
  write.fasta(sequences = as.list(seqs$asv_sequence), 
              names = seqs$asv_key,
              file.out = str_glue('../data/splitted_100/filtered_counts_asv_sequence_{i}.tsv'))
}
```

```{r}
# create bash script for creating the dir and then download only the file into the corresponding dir
src <- tibble(
  id = seq(1, 178),
  local_dir = str_glue('/Users/daia1/pipeline/scripts/picrust2/data/done_results/subset_{id}'),
  ko_file = str_glue('daia1@lilac.mskcc.org:~/my_workdir/other_pipeline/picrust2/output/picrust2_out_{id}/KO_metagenome_out/pred_metagenome_unstrat.tsv.gz'),
  pw_file = str_glue('daia1@lilac.mskcc.org:~/my_workdir/other_pipeline/picrust2/output/picrust2_out_{id}/pathways_out/path_abun_unstrat.tsv.gz'),
  dl_ko = str_glue('scp {ko_file} {local_dir}'),
  dl_pw = str_glue('scp {pw_file} {local_dir}'),
  unzip_ko = str_glue('gunzip /Users/daia1/pipeline/scripts/picrust2/data/done_results/subset_{id}/pred_metagenome_unstrat.tsv.gz'),
  unzip_pw = str_glue('gunzip /Users/daia1/pipeline/scripts/picrust2/data/done_results/subset_{id}/path_abun_unstrat.tsv.gz')
)

# create local dir first
src %>% 
  mutate(mkdir_cmd = str_glue('mkdir {local_dir}')) %>% 
  select(mkdir_cmd) %>% 
  write_tsv('../data/mkdir.sh', col_names = F)

src %>% 
  select(dl_ko, dl_pw, unzip_ko, unzip_pw) %>% 
  gather('fn', 'cmd') %>% 
  select(cmd) %>% 
  write_tsv('../data/downloding_ko_pw.sh', col_names = F)
```

